{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3e11c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rdflib import URIRef, BNode, Literal, Namespace\n",
    "from rdflib.namespace import DCTERMS, RDFS\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader, random_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import cycle, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e07c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "# if we use embedding only from last layer, this should stay as it is\n",
    "# it could be changed for some experiments ?\n",
    "layers = [-1]\n",
    "\n",
    "#we load the model\n",
    "#we could experiment with other models as well\n",
    "model = AutoModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f88ec4",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "- <del> split the texts into sentences\n",
    "- <del> filter the sentences that have 2+ entities AND have a relations among these\n",
    "\n",
    "\n",
    "- baseline prediction (matching the blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38740cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general functions\n",
    "#the device variable can be changed in case a GPU is available\n",
    "device = torch.device('cpu')\n",
    "#uncomment the next line to use gpu\n",
    "#device = torch.device('cuda')\n",
    "\n",
    "def split_sentences(sample):\n",
    "    sentence_boundaries = sample['sentences_boundaries']\n",
    "    sentences = []\n",
    "    text = sample[\"text\"]\n",
    "    for boundary in sentence_boundaries:\n",
    "        start= boundary[0]\n",
    "        end = boundary [1]\n",
    "        sentence = text[start:end]\n",
    "        sentences.append(sentence)\n",
    "    return sentences, sentence_boundaries\n",
    "\n",
    "def get_relations(sample):\n",
    "    sentence_list = []\n",
    "    sentences, sentence_boundaries = split_sentences(sample)\n",
    "    triples = sample['triples']\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_dict = {}\n",
    "        #it looks like some entities do not have boundaries, this would make it difficult to retrieve the tokens\n",
    "        #let's just not include them for now\n",
    "        triples_to_get = [x for x in triples if x['sentence_id'] == i and x['object']['boundaries'] != None and x['subject']['boundaries'] != None]\n",
    "        if len(triples_to_get) >= 1:\n",
    "            sentence_dict['sentence'] = sentence\n",
    "            for rel in triples_to_get:\n",
    "                if rel['predicate']['boundaries'] == None:\n",
    "                    rel['predicate']['boundaries'] = sentence_boundaries[i]\n",
    "                    \n",
    "            sentence_dict['triples'] = triples_to_get\n",
    "            sentence_dict['boundaries'] = sentence_boundaries[i]\n",
    "            sentence_list.append(sentence_dict)\n",
    "    return sentence_list\n",
    "    \n",
    "\n",
    "#the next two functions are used to extract the embeddings from tokens / sentences\n",
    "def get_hidden_states(encoded, model, layers):\n",
    "    with torch.no_grad():\n",
    "         output = model(**encoded)\n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_words_vector(sent, tokenizer, model, layers):\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    #token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "\n",
    "    return get_hidden_states(encoded, model, layers)\n",
    "\n",
    "def get_idx(string_list, boundaries, token_offsets):\n",
    "    ids = []\n",
    "    for r in range(len(string_list)):\n",
    "        len_string = len(' '.join(string_list[r:]))\n",
    "        offset = boundaries[1]-len_string\n",
    "        ids.append(token_offsets[offset][0])\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e786a60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [json.load(x) for x in glob.glob('./data/*.json')]\n",
    "data_sentences = []\n",
    "for file in data:\n",
    "    for doc in file:\n",
    "        for sentence in get_relations(doc):\n",
    "            data_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8903b3",
   "metadata": {},
   "source": [
    "for the sentence graph, we need:\n",
    "- <del> edge index\n",
    "- <del> edge labels / type\n",
    "- <del> node features\n",
    "- (maybe) edge feature\n",
    "\n",
    "\n",
    "- <del> dataframes [id_sentence, sentence_graph, sentence_string] || [id_sentence, relation, e1_node, e2_node] ||\n",
    "- <del> max num of nodes, num of dependencies relations (inside the graph), dimensionality (300), num of relations to predict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4adcc397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 / 17557\r"
     ]
    }
   ],
   "source": [
    "dict_sentences = {}\n",
    "graphs = []\n",
    "full_rels = []\n",
    "\n",
    "df_sent_columns = ['id_sentence', 'sentence_graph', 'sentence_string']\n",
    "df_rel_columns = ['id_sentence', 'relation_uri', 'relation_boundaries', 'e1_node', 'e2_node']\n",
    "\n",
    "df_sent = []\n",
    "df_rel = []\n",
    "\n",
    "dict_embeddings = {}\n",
    "\n",
    "for enum_sent, sentence in enumerate(data_sentences[:100]):\n",
    "    print(enum_sent, len(data_sentences), sep= ' / ', end='\\r')\n",
    "    sentence_id = f\"sentence_{enum_sent}\"\n",
    "\n",
    "    g = nx.Graph()\n",
    "    #dict_embeddings = {}\n",
    "    edge_list = []\n",
    "    starting_token = 0\n",
    "    relations_list = []\n",
    "\n",
    "    sentence_string = sentence['sentence'].replace('  ', ' ')\n",
    "    re.sub('\\W+',' ',sentence_string).strip()\n",
    "    sentence_boundaries = sentence['boundaries']\n",
    "    triples = sentence['triples']\n",
    "    token_offsets = {}\n",
    "    \n",
    "    sent_embeddings = get_words_vector(sentence_string, tokenizer, model, layers)\n",
    "    doc_spacy = nlp_en(sentence_string)\n",
    "    \n",
    "    for token in doc_spacy:\n",
    "        #print('>', repr(token))\n",
    "        enum_idx = 0\n",
    "        token_offsets[token.idx] = (token.i, token.text)\n",
    "        token_idx = tokenizer.encode(token.text, add_special_tokens=False)\n",
    "        \n",
    "        token_embeddings = []\n",
    "        for enum_idx, token_id in enumerate(token_idx):\n",
    "            #print(enum_idx,\n",
    "            #      token_id,\n",
    "            #      token.idx,\n",
    "            #      token.i+skipped_tokens,\n",
    "            #      sent_embeddings.shape,\n",
    "            #      tokenizer.convert_ids_to_tokens(token_id))\n",
    "            token_embeddings.append(sent_embeddings[starting_token + enum_idx])\n",
    "            \n",
    "        starting_token += 1\n",
    "        if len(token_embeddings) > 1:\n",
    "            token_embeddings = torch.stack(token_embeddings).to(device)\n",
    "            token_embeddings = torch.mean(token_embeddings, -2)\n",
    "\n",
    "        elif len(token_embeddings) == 1:\n",
    "            token_embeddings = torch.stack(token_embeddings).to(device)\n",
    "        else:\n",
    "            token_embeddings = torch.rand(1,768)\n",
    "\n",
    "        token_embeddings = torch.reshape(token_embeddings, (1,768))\n",
    "        #dict_embeddings[token.i] = token_embeddings        \n",
    "        start_token = token.idx\n",
    "        end_token = token.idx + len(token.text)\n",
    "        \n",
    "        g.add_node(token.i,\n",
    "                   label=token.text,\n",
    "                   type='token',\n",
    "                   #features=token_embeddings,\n",
    "                   boundaries=(start_token, end_token\n",
    "                              )\n",
    "                  )\n",
    "        token_id = f\"{sentence_id}_token_{token.i}\"\n",
    "        dict_embeddings[token_id] = token_embeddings\n",
    "        \n",
    "        edge_list.append((token.i, token.head.i, token.dep_))\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        g.add_edge(edge[0], edge[1], label=edge[2])\n",
    "    row_sent = [enum_sent, g, sentence_string]\n",
    "    df_sent.append(row_sent)\n",
    "    \n",
    "    \n",
    "    next_i = token.i + 1\n",
    "    \n",
    "    for triple in triples:\n",
    "\n",
    "        try:\n",
    "            subj_uri = triple['subject']['uri']\n",
    "            subj_string = triple['subject']['surfaceform']\n",
    "            subj_string_list = subj_string.split()\n",
    "            subj_boundaries = [x - sentence_boundaries[0] for x in triple['subject']['boundaries']]\n",
    "            \n",
    "            subj_ids = get_idx(subj_string_list, subj_boundaries, token_offsets)\n",
    "\n",
    "            obj_uri = triple['object']['uri']\n",
    "            obj_string = triple['object']['surfaceform']\n",
    "            obj_string_list = obj_string.split()\n",
    "            obj_boundaries = [x - sentence_boundaries[0] for x in triple['object']['boundaries']]\n",
    "            obj_ids = get_idx(obj_string_list, obj_boundaries, token_offsets)\n",
    "\n",
    "            relation_boundary_start = min([subj_boundaries[0], obj_boundaries[0]])\n",
    "            relation_boundary_end = max([subj_boundaries[1], obj_boundaries[1]])\n",
    "\n",
    "\n",
    "            ##-----these might be useful in future------\n",
    "            #rel_boundaries = triple['predicate']['boundaries']\n",
    "            rel_boundaries = [relation_boundary_start, relation_boundary_end]\n",
    "            rel_surfaceform = triple['predicate']['surfaceform']\n",
    "            rel_uri = triple['predicate']['uri']\n",
    "            relations_list.append((subj_ids, obj_ids, rel_uri))\n",
    "\n",
    "\n",
    "            text = data[0][triple['sentence_id']]['text']\n",
    "            ##----------------------------------------------\n",
    "            \n",
    "            subj_degrees = [g.degree(x) for x in subj_ids]\n",
    "            subj_id_index = np.argmax(subj_degrees)\n",
    "                        \n",
    "                \n",
    "            obj_degrees = [g.degree(x) for x in obj_ids]\n",
    "            obj_id_index = np.argmax(obj_degrees)\n",
    "            row_rel = [enum_sent,rel_uri, rel_boundaries, subj_ids[subj_id_index], obj_ids[obj_id_index]]\n",
    "            df_rel.append(row_rel)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "df_rel = pd.DataFrame(df_rel, columns=df_rel_columns)\n",
    "df_sent = pd.DataFrame(df_sent, columns = df_sent_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3cdaa",
   "metadata": {},
   "source": [
    "#### <del> TODO: DIMENSIONALITY REDUCTION </del>\n",
    "### DONE\n",
    "\n",
    "we will use the technique from https://github.com/vyraun/Half-Size (the code is in algo.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c44eec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code for dim. reduction\n",
    "#i have yet to read the full papers, but to my understanding the two n_components parameters are used \n",
    "# for two separate things:\n",
    "#the first one is needed in order to have some kind of filter at the beginning of the process\n",
    "#while the second one defines the final dimensionality\n",
    "\n",
    "def get_reduced_embeddings(dict_embedding, n_components_first_iteration=300, n_components_second_iteration=150):\n",
    "    reduced_embeddings = {}\n",
    "    X_names = list(dict_embeddings.keys())\n",
    "    X_train = np.asarray([np.asarray(dict_embeddings[k][0]) for k in X_names])\n",
    "    #print(X_train[0])\n",
    "    pca_embeddings = {}\n",
    "    pca = PCA(n_components=300)\n",
    "    X_train = X_train - np.mean(X_train)\n",
    "    X_fit = pca.fit_transform(X_train)\n",
    "    U1 = pca.components_\n",
    "\n",
    "    z = []\n",
    "    for i, x in enumerate(X_train):\n",
    "        for u in U1[0:7]:\n",
    "            x = x - np.dot(u.transpose(), x) * u\n",
    "        z.append(x)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    pca = PCA(n_components=150)\n",
    "    X_train = z-np.mean(z)\n",
    "    X_new_final = pca.fit_transform(X_train)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=150)\n",
    "    X_new = X_new_final - np.mean(X_new_final)\n",
    "    X_new = pca.fit_transform(X_new)\n",
    "\n",
    "    Ufit = pca.components_\n",
    "    X_new_final = X_new - np.mean(X_new)\n",
    "\n",
    "    for i, name in enumerate(X_names):\n",
    "        id_sentence = re.findall(r'sentence\\_[0-9]*', name)[0]\n",
    "        id_token = int(re.findall(r'token\\_([0-9]*)', name)[0])\n",
    "        if id_sentence not in reduced_embeddings:\n",
    "            reduced_embeddings[id_sentence] = {}\n",
    "        for u in Ufit[0:7]:\n",
    "            reduced_embeddings[id_sentence][id_token] = X_new_final[i] - np.dot(u.transpose(), X_new_final[i]) * u\n",
    "    return reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d28e28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = get_reduced_embeddings(dict_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cc51c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve embeddings with dimensionality reduction and put them as nodes' features\n",
    "for i, sent in df_sent.iterrows():\n",
    "    graph = sent['sentence_graph']\n",
    "    sentence_id = f\"sentence_{i}\"    \n",
    "    reduced_embedding_node = reduced_embeddings[sentence_id]\n",
    "    nx.set_node_attributes(graph, reduced_embedding_node, 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3fb14",
   "metadata": {},
   "source": [
    "#### TODO: Implement stream processing\n",
    "* implement the dataset as a PyTorch IterableDataset\n",
    "* randomize samples\n",
    "* split into train, validation, test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3fbaa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sentences = self.data.iloc[idx, 1:]\n",
    "        sentences = np.array(sentences)        \n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2e2d4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "### please check whether this is ok:\n",
    "### I first split the two datasets into train test and validation\n",
    "### then I create their iterable datasets\n",
    "### it looks like an iterable dataset cannot be split, so this might be the only way\n",
    "\n",
    "sent_train, sent_test = train_test_split(df_sent, test_size=0.2)\n",
    "sent_train, sent_dev = train_test_split(sent_train, test_size = 0.1)\n",
    "\n",
    "rel_train, rel_test = train_test_split(df_sent, test_size=0.2)\n",
    "rel_train, rel_dev = train_test_split(rel_train, test_size = 0.1)\n",
    "\n",
    "sent_train, sent_test, sent_dev = MyIterableDataset(sent_train), MyIterableDataset(sent_test), MyIterableDataset(sent_dev)\n",
    "rel_train, rel_test, rel_dev = MyIterableDataset(rel_train), MyIterableDataset(rel_test), MyIterableDataset(rel_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a85e7e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sentence_train = round(len(dataset_sentence)//0.8)\n",
    "len_sentence_test = round(len(dataset_sentence)-len_sentence_train)\n",
    "splits = random_split(dataset_sentence, [len_sentence_train, len_sentence_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset_sentence,\n",
    "                    batch_size=4,\n",
    "                   shuffle=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "64e96b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_num_of_nodes': 333,\n",
       " 'num_of_graph_relations': 45,\n",
       " 'num_of_dimension': 300,\n",
       " 'num_of_relations_to_predict': 78073}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = [x for x in df_rel['relation_uri']]\n",
    "\n",
    "args = {\n",
    "    \"max_num_of_nodes\" : max([len(g.nodes) for g in df_sent['sentence_graph']]),\n",
    "    \"num_of_graph_relations\" : len(nlp_en.get_pipe(\"parser\").labels),\n",
    "    \"num_of_dimension\" : 300,\n",
    "    \"num_of_relations_to_predict\": len(relations)\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "82c8767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAE, RGCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "48439e7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, feature_channels, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        # todo try FastRGCNConv as well, as we have GPUs with each 48GB VRAM\n",
    "        self.conv1 = RGCNConv(feature_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=8)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(hidden_channels * 2, num_relations)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        concat = torch.cat((z_src, z_dst), 1)\n",
    "        x = self.linear(concat)\n",
    "        return torch.nn.ReLU()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325e004",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "tensor(115.0607, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(114.5007, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(111.4412, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(111.2930, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(113.0909, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.5646, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.3330, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.1276, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(107.6038, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(102.7915, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(108.5110, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(107.8984, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(105.2052, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(103.2536, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(106.4586, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.9473, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(103.0833, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(100.9531, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.4009, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.5503, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(96.2559, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(101.1249, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(101.2919, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.2832, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(92.9472, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(79.7402, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.5830, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.5263, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.1224, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.4355, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.4086, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(107.3059, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.5479, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.6290, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.6125, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(105.1392, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.1235, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.9894, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(72.2745, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.9353, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(72.4486, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.6794, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.5708, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.9594, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.7347, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.8860, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.5294, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.0392, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(60.9137, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.9979, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.6107, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(55.6603, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.5260, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.9297, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.6354, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.3487, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.4371, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.0494, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.9858, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(58.9756, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.7981, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.2235, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.9801, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.0048, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.6624, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.7734, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.2072, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.4554, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(82.5315, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.4562, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.0915, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.4111, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(99.9752, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(99.7518, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.8997, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.2190, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.7016, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.3032, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.5210, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(100.1283, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(72.3445, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.8549, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.3145, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.3192, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(109.8035, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.9857, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.7653, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.9641, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.4407, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(95.8999, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(106.0708, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.8226, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.2616, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.2581, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.0996, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.2406, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.0108, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.2385, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.9812, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.3454, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.7108, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.6660, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.6079, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(92.1054, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.3910, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.2980, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.2785, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.8448, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.3370, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(116.8673, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(92.4364, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.1549, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.0584, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.5039, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(67.7184, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(60.0642, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.1370, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(42.3238, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.7698, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.1985, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.8894, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(46.1379, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.7793, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(110.9738, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(91.2799, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.0895, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.9781, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(67.6149, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(41.9845, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.5738, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.6310, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(52.0983, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(58.7364, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.4257, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(92.9634, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.5211, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.6866, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.4412, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.3794, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(100.5749, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.5760, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.7095, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(107.8811, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.2096, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(82.1666, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.2033, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.5875, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.4726, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.0906, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.5335, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.1245, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.6313, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.9713, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(97.8689, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.8589, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.4305, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.5031, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.0994, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.8398, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.2145, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.3945, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(98.9674, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.0990, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.6811, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.8527, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.8482, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.5349, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.1952, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.1154, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(92.1809, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.6955, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(55.8193, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(105.9117, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.1288, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.5833, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.4530, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.8974, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.2360, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.9006, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(67.6287, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.4775, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.1853, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.8036, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.1127, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(107.9275, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.4448, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.1833, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.2165, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(41.2740, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.7882, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.9466, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.4653, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.5297, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.0623, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(98.5467, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.0166, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.1495, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.8053, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(60.1550, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(79.9020, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.1142, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.6811, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.2732, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.8529, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.9180, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.1853, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.9016, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.6649, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.0540, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.0891, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.9365, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.3738, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.2642, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(82.4111, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.0442, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.1878, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(82.1609, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(41.5838, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(58.7737, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(58.9376, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.6448, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.2194, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.4747, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.4381, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.0116, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.5181, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.9484, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.2373, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(71.3966, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(55.3517, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.0006, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.8991, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.3139, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.2523, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.5914, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.2711, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.5337, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(27.5679, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.4140, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.4270, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.0552, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.6358, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.5978, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(50.1597, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.6678, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.8762, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(71.4024, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(88.4672, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.1548, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(91.5979, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.5389, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.1218, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.1171, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(91.2754, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(40.4585, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.6931, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.0027, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.6212, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(54.9648, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(52.4338, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.7273, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.2332, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(38.6047, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.2147, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.8815, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.2247, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(50.5343, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(39.8022, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.9323, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(22.7229, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.5926, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.3761, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.6201, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(52.7796, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.4211, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.5056, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.7918, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.2104, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(36.6095, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(57.1373, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(42.0459, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.3960, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.7753, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.6699, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(103.6087, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.6605, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.4113, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(102.1784, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.3053, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.0712, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.0490, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(102.3841, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(99.9696, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.2641, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.3484, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(98.6869, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(46.1658, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(34.5396, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(49.4068, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.5118, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.0424, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.4309, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.7984, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.8266, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.3596, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.4872, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.6606, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(46.3941, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.6939, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(49.5182, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(52.1354, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.0430, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(105.8021, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(40.9122, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.8619, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.7022, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.6298, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.8807, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.2224, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.5450, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.5684, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.5396, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.2038, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.3016, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.3486, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.0656, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.1451, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(37.3037, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(79.8107, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.6446, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(54.4390, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.2484, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.2997, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(115.1181, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(108.8164, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(94.7659, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.3029, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.3356, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(96.1198, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.5767, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.0815, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.2716, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.3092, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(86.0716, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(102.2788, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.3828, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.1658, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.6718, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(100.1602, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.2302, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(89.6566, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(96.5987, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.9536, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(79.9654, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.2401, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.3978, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.8199, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.4118, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(95.9883, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.7973, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(54.7098, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.2526, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.0683, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.6144, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.5724, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(55.3718, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.7773, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.8499, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.5026, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.7912, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(55.5226, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.2007, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.4419, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(57.0314, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(69.9491, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(93.3263, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(49.3552, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.5271, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(104.0660, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.0715, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(87.1475, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.9684, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.5525, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.4751, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(72.1758, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.0860, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.4999, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(99.0911, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(96.3827, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(57.5650, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(83.3839, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.4984, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.0957, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.1214, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.4057, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.9562, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(59.2258, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.9876, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(100.2081, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(56.2293, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(82.5545, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(76.9463, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(63.7370, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(111.8707, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.3766, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.1683, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.3472, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.3467, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.5815, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.5845, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.4590, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.9881, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(79.3751, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.6633, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.6697, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.0509, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.6356, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(99.4381, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.3978, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(95.6645, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(78.6638, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.0395, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(57.4883, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.5760, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.1187, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(77.3253, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(67.0973, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.2317, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(74.4599, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.7426, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.9506, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(65.9830, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(90.6745, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(66.1959, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(35.6448, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(81.0796, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(84.6282, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(73.2825, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.9003, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(35.9534, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(32.9730, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.4941, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(37.1284, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(26.0797, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(85.5479, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(62.7054, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(22.1525, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.3873, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(34.6865, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(47.2892, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.4529, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.6771, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.6648, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(45.9326, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.7435, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.2098, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(37.0598, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(48.8824, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(80.4363, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(42.1074, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(51.8706, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(68.7517, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(75.6605, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(61.6694, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(52.8778, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(58.7305, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(54.9233, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(54.5757, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(64.0240, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(50.3205, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(39.2385, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(49.5752, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(70.2489, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(43.3163, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(67.2830, grad_fn=<AddBackward0>)\n",
      "batch\n",
      "tensor(53.7586, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "model = GAE(\n",
    "    RGCNEncoder(feature_channels=768,\n",
    "                hidden_channels=200,\n",
    "                num_relations=args[\"num_of_graph_relations\"]),\n",
    "    Decoder(args[\"num_of_relations_to_predict\"],\n",
    "            hidden_channels=200),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "graphs = []\n",
    "for idx, sentence_graph in df_sent[['id_sentence', 'sentence_graph']].iterrows():\n",
    "\n",
    "    g = Data(x=torch.stack([sentence_graph['sentence_graph'].nodes[id_node]['features'].flatten(0) for id_node in sentence_graph['sentence_graph'].nodes]),\n",
    "             edge_index=torch.tensor(list(sentence_graph['sentence_graph'].edges())).T,\n",
    "             y=sentence_graph['id_sentence'],\n",
    "             edge_type=torch.tensor([nlp_en.get_pipe(\"parser\").labels.index(sentence_graph['sentence_graph'].get_edge_data(x,y)['label']) for (x,y) in sentence_graph['sentence_graph'].edges()]))\n",
    "    graphs.append(g)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(graphs, batch_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "# todo how to parallelize?\n",
    "for epoch in range(0, 100):\n",
    "    for batch in dataloader:\n",
    "        cross_entropy_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # todo implement batch processing for the RGCN that does not need the number of edges in advance (use pty to construct the new node id that is used in the batch)\n",
    "        for i in range(batch_size):\n",
    "            sample = batch.get_example(i)\n",
    "            id_sentence = sample.y.item()\n",
    "\n",
    "            e1_nodes = torch.tensor(df_rel.loc[df_rel['id_sentence'] == id_sentence]['e1_node'].values)\n",
    "            e2_nodes = torch.tensor(df_rel.loc[df_rel['id_sentence'] == id_sentence]['e2_node'].values)\n",
    "            edge_index_relations = torch.stack([e1_nodes, e2_nodes])\n",
    "            y_true = torch.tensor([relations.index(r) for r in df_rel.loc[df_rel['id_sentence'] == id_sentence]['relation_uri'].values])\n",
    "\n",
    "            if y_true.size(0) > 0:\n",
    "                z = model.encode(sample.x, sample.edge_index, sample.edge_type)\n",
    "                y_pred = model.decode(z, edge_index_relations)\n",
    "                l = loss_function(y_pred, y_true)\n",
    "                cross_entropy_loss += l\n",
    "\n",
    "        print(cross_entropy_loss)\n",
    "        if torch.is_tensor(cross_entropy_loss) and cross_entropy_loss.requires_grad:\n",
    "            cross_entropy_loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cb56cbb4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96626a20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b36ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
