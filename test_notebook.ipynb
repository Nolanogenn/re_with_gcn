{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3e11c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from rdflib import URIRef, BNode, Literal, Namespace\n",
    "from rdflib.namespace import DCTERMS, RDFS\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "# if we use embedding only from last layer, this should stay as it is\n",
    "# it could be changed for some experiments ?\n",
    "layers = [-1]\n",
    "\n",
    "#we load the model\n",
    "#we could experiment with other models as well\n",
    "model = AutoModel.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525e55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.load(open(x)) for x in glob.glob('./data/*.json')[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e187bf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_id': 0,\n",
       " 'predicate': {'boundaries': None,\n",
       "  'surfaceform': None,\n",
       "  'uri': 'http://www.wikidata.org/prop/direct/P31',\n",
       "  'annotator': 'NoSubject-Triple-aligner'},\n",
       " 'object': {'boundaries': [94, 109],\n",
       "  'surfaceform': 'language family',\n",
       "  'uri': 'http://www.wikidata.org/entity/Q25295',\n",
       "  'annotator': 'Wikidata_Spotlight_Entity_Linker'},\n",
       " 'dependency_path': None,\n",
       " 'confidence': None,\n",
       " 'subject': {'boundaries': [4, 27],\n",
       "  'surfaceform': 'Austroasiatic languages',\n",
       "  'uri': 'http://www.wikidata.org/entity/Q33199',\n",
       "  'annotator': 'Wikidata_Spotlight_Entity_Linker'},\n",
       " 'annotator': 'NoSubject-Triple-aligner'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]['triples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e38740cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general functions\n",
    "#the device variable can be changed in case a GPU is available\n",
    "device = torch.device('cpu')\n",
    "#uncomment the next line to use gpu\n",
    "#device = torch.device('gpu')\n",
    "\n",
    "#the next two functions are used to extract the embeddings from tokens / sentences\n",
    "def get_hidden_states(encoded, model, layers):\n",
    "    with torch.no_grad():\n",
    "         output = model(**encoded)\n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_words_vector(sent, tokenizer, model, layers):\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    #token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "\n",
    "    return get_hidden_states(encoded, model, layers)\n",
    "\n",
    "def get_idx(string_list, boundaries, token_offsets):\n",
    "    ids = []\n",
    "    for r in range(len(string_list)):\n",
    "        len_string = len(' '.join(string_list[r:]))\n",
    "        offset = boundaries[1]-len_string\n",
    "        ids.append(token_offsets[offset][0])\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4adcc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sentence = {}\n",
    "\n",
    "graphs = []\n",
    "full_rels = []\n",
    "\n",
    "for enum_doc, doc in enumerate(data[0][:5]):\n",
    "    g = nx.Graph()\n",
    "    dict_embeddings = {}\n",
    "    edge_list = []\n",
    "    skipped_tokens = 0\n",
    "    relations_list = []\n",
    "\n",
    "    string = doc['text']\n",
    "    triples = doc['triples']\n",
    "    token_offsets = {}\n",
    "    \n",
    "    sent_embeddings = get_words_vector(string, tokenizer, model, layers)\n",
    "\n",
    "    doc_spacy = nlp_en(string)\n",
    "    for token in doc_spacy:\n",
    "        token_offsets[token.idx] = (token.i, token.text)\n",
    "        \n",
    "        #bert_token = tokenizer.tokenize(token.string, add_special_tokens=False)\n",
    "        token_idx = tokenizer.encode(token.text, add_special_tokens=False)\n",
    "        \n",
    "        token_embeddings = []\n",
    "        for enum_idx, token_id in enumerate(token_idx):\n",
    "            token_embeddings.append(sent_embeddings[token.i+enum_idx+skipped_tokens])\n",
    "        skipped_tokens += enum_idx\n",
    "\n",
    "            \n",
    "        if len(token_embeddings) > 1:\n",
    "            token_embeddings = torch.stack(token_embeddings).to(device)\n",
    "            token_embeddings = torch.mean(token_embeddings, -2)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                token_embeddings = token_embeddings[0]\n",
    "            except:\n",
    "                pass\n",
    "        token_embeddings = torch.reshape(token_embeddings, (1,768))\n",
    "\n",
    "            \n",
    "        dict_embeddings[token.i] = token_embeddings\n",
    "        g.add_node(token.i, label=token.text, type='token')\n",
    "        edge_list.append((token.i, token.head.i))\n",
    "    \n",
    "    next_i = token.i + 1\n",
    "    \n",
    "    for triple in triples:\n",
    "        try:\n",
    "            subj_uri = triple['subject']['uri']\n",
    "            subj_string = triple['subject']['surfaceform']\n",
    "            subj_string_list = subj_string.split()\n",
    "            subj_boundaries = triple['subject']['boundaries']\n",
    "            subj_ids = get_idx(subj_string_list, subj_boundaries, token_offsets)\n",
    "\n",
    "            obj_uri = triple['object']['uri']\n",
    "            obj_string = triple['object']['surfaceform']\n",
    "            obj_string_list = obj_string.split()\n",
    "            obj_boundaries = triple['object']['boundaries']\n",
    "            obj_ids = get_idx(obj_string_list, obj_boundaries, token_offsets)\n",
    "            \n",
    "            embeddings_subj = []\n",
    "            embeddings_obj = []\n",
    "            \n",
    "            subj_i = int(next_i)\n",
    "            obj_i = int(next_i+1)\n",
    "            g.add_node(subj_i, label=subj_string, type='entity')\n",
    "            for i in subj_ids:\n",
    "                embeddings_subj.append(dict_embeddings[i])\n",
    "                edge_list.append((i, subj_i))\n",
    "                \n",
    "            g.add_node(obj_i, label=obj_string, type='entity')\n",
    "            for i in obj_ids:\n",
    "                embeddings_obj.append(dict_embeddings[i])\n",
    "                edge_list.append((i, obj_i))\n",
    "            \n",
    "            if len(embeddings_subj) > 1:\n",
    "                embeddings_subj = torch.stack(embeddings_subj).to(device)\n",
    "                embeddings_subj = torch.mean(embeddings_subj, -2)\n",
    "            else:\n",
    "                embeddings_subj = torch.stack(embeddings_subj).to(device)\n",
    "            \n",
    "           \n",
    "            if len(embeddings_obj) > 1:\n",
    "                embeddings_obj = torch.stack(embeddings_obj).to(device)\n",
    "                embeddings_obj = torch.mean(embeddings_obj, -2)\n",
    "            else:\n",
    "                embeddings_obj = torch.stack(embeddings_obj).to(device) \n",
    "                \n",
    "                \n",
    "            dict_embeddings[subj_i] = embeddings_subj\n",
    "            dict_embeddings[obj_i] = embeddings_obj\n",
    "\n",
    "            next_i += 2\n",
    "\n",
    "            ##-----these might be useful in future------\n",
    "            rel_boundaries = triple['predicate']['boundaries']\n",
    "            rel_surfaceform = triple['predicate']['surfaceform']\n",
    "            rel_uri = triple['predicate']['uri']\n",
    "            relations_list.append((subj_i, obj_i, rel_uri))\n",
    "\n",
    "            text = data[0][triple['sentence_id']]['text']\n",
    "            ##----------------------------------------------\n",
    "             \n",
    "            predicate_string = data[0][0]['text'][min(obj_boundaries[0], subj_boundaries[0]):max(obj_boundaries[1],subj_boundaries[1])] if rel_boundaries == None else data[0][0]['text'][rel_boundaries[0]:rel_boundaries[1]]    \n",
    "        except TypeError:\n",
    "            pass\n",
    "    g.add_edges_from(edge_list)\n",
    "    graphs.append(g)\n",
    "    full_rels.append(relations_list)\n",
    "    dict_sentence[enum_doc] = dict_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "448420c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 253, 'http://www.wikidata.org/prop/direct/P31')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "90f4e7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'language family', 'type': 'entity'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].nodes[253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3264b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e0be62e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8767c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
